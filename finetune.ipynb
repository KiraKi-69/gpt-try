{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15435255-8f45-4c4c-acda-898e40802737",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcf5c90-e730-4bb0-9a53-01322a3e5abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python run_clm.py \\\n",
    "#     --model_name_or_path sberbank-ai/rugpt3small_based_on_gpt2 \\\n",
    "#     --train_file train.txt \\\n",
    "#     --validation_file valid.txt \\\n",
    "#     --per_device_train_batch_size 1 \\\n",
    "#     --per_device_eval_batch_size 1 \\\n",
    "#     --block_size 2048 \\\n",
    "#     --dataset_config_name plain_text \\\n",
    "#     --do_train \\\n",
    "#     --output_dir model/essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c269459b-2eaa-4a44-86e5-e42c7e8c6bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/22/2023 12:36:58 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "08/22/2023 12:36:58 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=models/rugpt3small\\runs\\Aug22_12-36-58_DESKTOP-N5JARSG,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=12.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=models/rugpt3small,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=1,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['mlflow'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=models/rugpt3small,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=False,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "08/22/2023 12:36:59 - INFO - datasets.builder - Using custom data configuration default-6836e6333b631ed6\n",
      "08/22/2023 12:36:59 - INFO - datasets.info - Loading Dataset Infos from D:\\Projects\\gpt_venv\\lib\\site-packages\\datasets\\packaged_modules\\text\n",
      "08/22/2023 12:36:59 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "08/22/2023 12:36:59 - INFO - datasets.info - Loading Dataset info from C:\\Users\\GANS\\.cache\\huggingface\\datasets\\text\\default-6836e6333b631ed6\\0.0.0\\c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34\n",
      "08/22/2023 12:36:59 - INFO - datasets.builder - Found cached dataset text (C:/Users/GANS/.cache/huggingface/datasets/text/default-6836e6333b631ed6/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34)\n",
      "08/22/2023 12:36:59 - INFO - datasets.info - Loading Dataset info from C:/Users/GANS/.cache/huggingface/datasets/text/default-6836e6333b631ed6/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34\n",
      "08/22/2023 12:37:00 - INFO - datasets.builder - Using custom data configuration default-6836e6333b631ed6\n",
      "08/22/2023 12:37:00 - INFO - datasets.info - Loading Dataset Infos from D:\\Projects\\gpt_venv\\lib\\site-packages\\datasets\\packaged_modules\\text\n",
      "08/22/2023 12:37:00 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "08/22/2023 12:37:00 - INFO - datasets.info - Loading Dataset info from C:\\Users\\GANS\\.cache\\huggingface\\datasets\\text\\default-6836e6333b631ed6\\0.0.0\\c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34\n",
      "08/22/2023 12:37:00 - INFO - datasets.builder - Found cached dataset text (C:/Users/GANS/.cache/huggingface/datasets/text/default-6836e6333b631ed6/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34)\n",
      "08/22/2023 12:37:00 - INFO - datasets.info - Loading Dataset info from C:/Users/GANS/.cache/huggingface/datasets/text/default-6836e6333b631ed6/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34\n",
      "08/22/2023 12:37:01 - INFO - datasets.builder - Using custom data configuration default-6836e6333b631ed6\n",
      "08/22/2023 12:37:01 - INFO - datasets.info - Loading Dataset Infos from D:\\Projects\\gpt_venv\\lib\\site-packages\\datasets\\packaged_modules\\text\n",
      "08/22/2023 12:37:01 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "08/22/2023 12:37:01 - INFO - datasets.info - Loading Dataset info from C:\\Users\\GANS\\.cache\\huggingface\\datasets\\text\\default-6836e6333b631ed6\\0.0.0\\c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34\n",
      "08/22/2023 12:37:01 - INFO - datasets.builder - Found cached dataset text (C:/Users/GANS/.cache/huggingface/datasets/text/default-6836e6333b631ed6/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34)\n",
      "08/22/2023 12:37:01 - INFO - datasets.info - Loading Dataset info from C:/Users/GANS/.cache/huggingface/datasets/text/default-6836e6333b631ed6/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34\n",
      "08/22/2023 12:37:08 - INFO - datasets.arrow_dataset - Loading cached processed dataset at C:\\Users\\GANS\\.cache\\huggingface\\datasets\\text\\default-6836e6333b631ed6\\0.0.0\\c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34\\cache-c8858b69de20657d.arrow\n",
      "08/22/2023 12:37:08 - INFO - datasets.arrow_dataset - Loading cached processed dataset at C:\\Users\\GANS\\.cache\\huggingface\\datasets\\text\\default-6836e6333b631ed6\\0.0.0\\c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34\\cache-adfe252fcb624061.arrow\n",
      "08/22/2023 12:37:08 - INFO - datasets.arrow_dataset - Loading cached processed dataset at C:\\Users\\GANS\\.cache\\huggingface\\datasets\\text\\default-6836e6333b631ed6\\0.0.0\\c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34\\cache-09a34ef734fa0d39.arrow\n",
      "08/22/2023 12:37:08 - INFO - datasets.arrow_dataset - Loading cached processed dataset at C:\\Users\\GANS\\.cache\\huggingface\\datasets\\text\\default-6836e6333b631ed6\\0.0.0\\c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34\\cache-15621b110619e47c.arrow\n",
      "{'train_runtime': 429.9341, 'train_samples_per_second': 0.112, 'train_steps_per_second': 0.112, 'train_loss': 0.22293190161387125, 'epoch': 12.0}\n",
      "***** train metrics *****\n",
      "  epoch                    =       12.0\n",
      "  train_loss               =     0.2229\n",
      "  train_runtime            = 0:07:09.93\n",
      "  train_samples            =          4\n",
      "  train_samples_per_second =      0.112\n",
      "  train_steps_per_second   =      0.112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-6836e6333b631ed6\n",
      "Loading Dataset Infos from D:\\Projects\\gpt_venv\\lib\\site-packages\\datasets\\packaged_modules\\text\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from C:\\Users\\GANS\\.cache\\huggingface\\datasets\\text\\default-6836e6333b631ed6\\0.0.0\\c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34\n",
      "Found cached dataset text (C:/Users/GANS/.cache/huggingface/datasets/text/default-6836e6333b631ed6/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34)\n",
      "Loading Dataset info from C:/Users/GANS/.cache/huggingface/datasets/text/default-6836e6333b631ed6/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34\n",
      "Using custom data configuration default-6836e6333b631ed6\n",
      "Loading Dataset Infos from D:\\Projects\\gpt_venv\\lib\\site-packages\\datasets\\packaged_modules\\text\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from C:\\Users\\GANS\\.cache\\huggingface\\datasets\\text\\default-6836e6333b631ed6\\0.0.0\\c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34\n",
      "Found cached dataset text (C:/Users/GANS/.cache/huggingface/datasets/text/default-6836e6333b631ed6/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34)\n",
      "Loading Dataset info from C:/Users/GANS/.cache/huggingface/datasets/text/default-6836e6333b631ed6/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34\n",
      "Using custom data configuration default-6836e6333b631ed6\n",
      "Loading Dataset Infos from D:\\Projects\\gpt_venv\\lib\\site-packages\\datasets\\packaged_modules\\text\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from C:\\Users\\GANS\\.cache\\huggingface\\datasets\\text\\default-6836e6333b631ed6\\0.0.0\\c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34\n",
      "Found cached dataset text (C:/Users/GANS/.cache/huggingface/datasets/text/default-6836e6333b631ed6/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34)\n",
      "Loading Dataset info from C:/Users/GANS/.cache/huggingface/datasets/text/default-6836e6333b631ed6/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34\n",
      "[INFO|configuration_utils.py:712] 2023-08-22 12:37:04,046 >> loading configuration file config.json from cache at C:\\Users\\GANS/.cache\\huggingface\\hub\\models--sberbank-ai--rugpt3small_based_on_gpt2\\snapshots\\d64244b316057f71e745cc92be1dcfe7853d9d18\\config.json\n",
      "[INFO|configuration_utils.py:768] 2023-08-22 12:37:04,046 >> Model config GPT2Config {\n",
      "  \"_name_or_path\": \"sberbank-ai/rugpt3small_based_on_gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 2048,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 2048,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.31.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:512] 2023-08-22 12:37:04,571 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:712] 2023-08-22 12:37:05,093 >> loading configuration file config.json from cache at C:\\Users\\GANS/.cache\\huggingface\\hub\\models--sberbank-ai--rugpt3small_based_on_gpt2\\snapshots\\d64244b316057f71e745cc92be1dcfe7853d9d18\\config.json\n",
      "[INFO|configuration_utils.py:768] 2023-08-22 12:37:05,094 >> Model config GPT2Config {\n",
      "  \"_name_or_path\": \"sberbank-ai/rugpt3small_based_on_gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 2048,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 2048,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.31.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1839] 2023-08-22 12:37:06,139 >> loading file vocab.json from cache at C:\\Users\\GANS/.cache\\huggingface\\hub\\models--sberbank-ai--rugpt3small_based_on_gpt2\\snapshots\\d64244b316057f71e745cc92be1dcfe7853d9d18\\vocab.json\n",
      "[INFO|tokenization_utils_base.py:1839] 2023-08-22 12:37:06,139 >> loading file merges.txt from cache at C:\\Users\\GANS/.cache\\huggingface\\hub\\models--sberbank-ai--rugpt3small_based_on_gpt2\\snapshots\\d64244b316057f71e745cc92be1dcfe7853d9d18\\merges.txt\n",
      "[INFO|tokenization_utils_base.py:1839] 2023-08-22 12:37:06,139 >> loading file tokenizer.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1839] 2023-08-22 12:37:06,139 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1839] 2023-08-22 12:37:06,139 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1839] 2023-08-22 12:37:06,139 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:712] 2023-08-22 12:37:06,139 >> loading configuration file config.json from cache at C:\\Users\\GANS/.cache\\huggingface\\hub\\models--sberbank-ai--rugpt3small_based_on_gpt2\\snapshots\\d64244b316057f71e745cc92be1dcfe7853d9d18\\config.json\n",
      "[INFO|configuration_utils.py:768] 2023-08-22 12:37:06,140 >> Model config GPT2Config {\n",
      "  \"_name_or_path\": \"sberbank-ai/rugpt3small_based_on_gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 2048,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 2048,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.31.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:712] 2023-08-22 12:37:06,203 >> loading configuration file config.json from cache at C:\\Users\\GANS/.cache\\huggingface\\hub\\models--sberbank-ai--rugpt3small_based_on_gpt2\\snapshots\\d64244b316057f71e745cc92be1dcfe7853d9d18\\config.json\n",
      "[INFO|configuration_utils.py:768] 2023-08-22 12:37:06,204 >> Model config GPT2Config {\n",
      "  \"_name_or_path\": \"sberbank-ai/rugpt3small_based_on_gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 2048,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 2048,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.31.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "[WARNING|logging.py:280] 2023-08-22 12:37:06,259 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|modeling_utils.py:2603] 2023-08-22 12:37:06,269 >> loading weights file pytorch_model.bin from cache at C:\\Users\\GANS/.cache\\huggingface\\hub\\models--sberbank-ai--rugpt3small_based_on_gpt2\\snapshots\\d64244b316057f71e745cc92be1dcfe7853d9d18\\pytorch_model.bin\n",
      "[INFO|configuration_utils.py:599] 2023-08-22 12:37:06,479 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.31.0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3329] 2023-08-22 12:37:07,634 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "[INFO|modeling_utils.py:3337] 2023-08-22 12:37:07,634 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at sberbank-ai/rugpt3small_based_on_gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "[INFO|modeling_utils.py:2949] 2023-08-22 12:37:08,182 >> Generation config file not found, using a generation config created from the model config.\n",
      "Loading cached processed dataset at C:\\Users\\GANS\\.cache\\huggingface\\datasets\\text\\default-6836e6333b631ed6\\0.0.0\\c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34\\cache-c8858b69de20657d.arrow\n",
      "Loading cached processed dataset at C:\\Users\\GANS\\.cache\\huggingface\\datasets\\text\\default-6836e6333b631ed6\\0.0.0\\c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34\\cache-adfe252fcb624061.arrow\n",
      "Loading cached processed dataset at C:\\Users\\GANS\\.cache\\huggingface\\datasets\\text\\default-6836e6333b631ed6\\0.0.0\\c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34\\cache-09a34ef734fa0d39.arrow\n",
      "Loading cached processed dataset at C:\\Users\\GANS\\.cache\\huggingface\\datasets\\text\\default-6836e6333b631ed6\\0.0.0\\c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34\\cache-15621b110619e47c.arrow\n",
      "D:\\Projects\\gpt_venv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:1686] 2023-08-22 12:37:08,766 >> ***** Running training *****\n",
      "[INFO|trainer.py:1687] 2023-08-22 12:37:08,766 >>   Num examples = 4\n",
      "[INFO|trainer.py:1688] 2023-08-22 12:37:08,766 >>   Num Epochs = 12\n",
      "[INFO|trainer.py:1689] 2023-08-22 12:37:08,766 >>   Instantaneous batch size per device = 1\n",
      "[INFO|trainer.py:1692] 2023-08-22 12:37:08,766 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "[INFO|trainer.py:1693] 2023-08-22 12:37:08,766 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1694] 2023-08-22 12:37:08,766 >>   Total optimization steps = 48\n",
      "[INFO|trainer.py:1695] 2023-08-22 12:37:08,766 >>   Number of trainable parameters = 125,231,616\n",
      "\n",
      "  0%|          | 0/48 [00:00<?, ?it/s]\n",
      "  2%|2         | 1/48 [00:12<09:42, 12.39s/it]\n",
      "  4%|4         | 2/48 [00:21<07:49, 10.20s/it]\n",
      "  6%|6         | 3/48 [00:29<07:04,  9.43s/it]\n",
      "  8%|8         | 4/48 [00:38<06:38,  9.06s/it]\n",
      " 10%|#         | 5/48 [00:46<06:21,  8.87s/it]\n",
      " 12%|#2        | 6/48 [00:55<06:07,  8.75s/it]\n",
      " 15%|#4        | 7/48 [01:03<05:55,  8.67s/it]\n",
      " 17%|#6        | 8/48 [01:12<05:44,  8.61s/it]\n",
      " 19%|#8        | 9/48 [01:20<05:34,  8.58s/it]\n",
      " 21%|##        | 10/48 [01:29<05:26,  8.60s/it]\n",
      " 23%|##2       | 11/48 [01:37<05:17,  8.58s/it]\n",
      " 25%|##5       | 12/48 [01:46<05:07,  8.55s/it]\n",
      " 27%|##7       | 13/48 [01:54<04:59,  8.54s/it]\n",
      " 29%|##9       | 14/48 [02:03<04:50,  8.53s/it]\n",
      " 31%|###1      | 15/48 [02:11<04:41,  8.53s/it]\n",
      " 33%|###3      | 16/48 [02:20<04:32,  8.52s/it]\n",
      " 35%|###5      | 17/48 [02:28<04:23,  8.51s/it]\n",
      " 38%|###7      | 18/48 [02:37<04:15,  8.51s/it]\n",
      " 40%|###9      | 19/48 [02:45<04:07,  8.52s/it]\n",
      " 42%|####1     | 20/48 [02:54<03:58,  8.52s/it]\n",
      " 44%|####3     | 21/48 [03:02<03:49,  8.51s/it]\n",
      " 46%|####5     | 22/48 [03:11<03:41,  8.52s/it]\n",
      " 48%|####7     | 23/48 [03:19<03:32,  8.51s/it]\n",
      " 50%|#####     | 24/48 [03:28<03:24,  8.51s/it]\n",
      " 52%|#####2    | 25/48 [03:36<03:15,  8.51s/it]\n",
      " 54%|#####4    | 26/48 [03:45<03:07,  8.50s/it]\n",
      " 56%|#####6    | 27/48 [03:53<02:58,  8.51s/it]\n",
      " 58%|#####8    | 28/48 [04:02<02:50,  8.50s/it]\n",
      " 60%|######    | 29/48 [04:10<02:41,  8.51s/it]\n",
      " 62%|######2   | 30/48 [04:19<02:33,  8.51s/it]\n",
      " 65%|######4   | 31/48 [04:28<02:25,  8.53s/it]\n",
      " 67%|######6   | 32/48 [04:36<02:16,  8.52s/it]\n",
      " 69%|######8   | 33/48 [04:45<02:07,  8.51s/it]\n",
      " 71%|#######   | 34/48 [04:53<01:59,  8.56s/it]\n",
      " 73%|#######2  | 35/48 [05:02<01:51,  8.55s/it]\n",
      " 75%|#######5  | 36/48 [05:10<01:42,  8.54s/it]\n",
      " 77%|#######7  | 37/48 [05:19<01:33,  8.53s/it]\n",
      " 79%|#######9  | 38/48 [05:27<01:25,  8.53s/it]\n",
      " 81%|########1 | 39/48 [05:37<01:21,  9.02s/it]\n",
      " 83%|########3 | 40/48 [05:49<01:17,  9.74s/it]\n",
      " 85%|########5 | 41/48 [05:59<01:08,  9.73s/it]\n",
      " 88%|########7 | 42/48 [06:09<00:58,  9.80s/it]\n",
      " 90%|########9 | 43/48 [06:18<00:48,  9.63s/it]\n",
      " 92%|#########1| 44/48 [06:27<00:38,  9.58s/it]\n",
      " 94%|#########3| 45/48 [06:37<00:29,  9.69s/it]\n",
      " 96%|#########5| 46/48 [06:47<00:19,  9.64s/it]\n",
      " 98%|#########7| 47/48 [06:58<00:10, 10.02s/it]\n",
      "100%|##########| 48/48 [07:09<00:00, 10.40s/it][INFO|trainer.py:1934] 2023-08-22 12:44:18,391 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\n",
      "                                               \n",
      "\n",
      "100%|##########| 48/48 [07:09<00:00, 10.40s/it]\n",
      "100%|##########| 48/48 [07:09<00:00,  8.95s/it]\n",
      "[INFO|trainer.py:2807] 2023-08-22 12:44:18,706 >> Saving model checkpoint to models/rugpt3small\n",
      "[INFO|configuration_utils.py:458] 2023-08-22 12:44:18,707 >> Configuration saved in models/rugpt3small\\config.json\n",
      "[INFO|configuration_utils.py:375] 2023-08-22 12:44:18,708 >> Configuration saved in models/rugpt3small\\generation_config.json\n",
      "[INFO|modeling_utils.py:1851] 2023-08-22 12:44:22,016 >> Model weights saved in models/rugpt3small\\pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2210] 2023-08-22 12:44:22,017 >> tokenizer config file saved in models/rugpt3small\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2217] 2023-08-22 12:44:22,018 >> Special tokens file saved in models/rugpt3small\\special_tokens_map.json\n",
      "[INFO|modelcard.py:452] 2023-08-22 12:44:23,929 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"
     ]
    }
   ],
   "source": [
    "!python run_clm.py \\\n",
    "    --model_name_or_path sberbank-ai/rugpt3small_based_on_gpt2 \\\n",
    "    --train_file train.txt \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --block_size 2048 \\\n",
    "    --dataset_config_name plain_text \\\n",
    "    --do_train \\\n",
    "    --num_train_epochs 12 \\\n",
    "    --output_dir models/rugpt3small \\\n",
    "    --overwrite_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5268ee9-e7d3-45fd-9371-c3241e16bbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_clm.py \\\n",
    "    --model_name_or_path sberbank-ai/rugpt3medium_based_on_gpt2 \\\n",
    "    --train_file train.txt \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --block_size 2048 \\\n",
    "    --dataset_config_name plain_text \\\n",
    "    --do_train \\\n",
    "    --num_train_epochs 12 \\\n",
    "    --output_dir models/rugpt3small \\\n",
    "    --overwrite_output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda4a626-d665-4b9a-94dd-336c87537f27",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26bbb307-bbfb-41f6-892f-3469bf602467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c471be0-5a80-400b-bf38-64f30b3f9234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1654d1a23b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a71f121-e24e-4e75-b572-459d4f3753da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd9f50d-3532-4f12-ba1a-2a91059a4747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd0f16ff-af6c-47cc-a3ac-cc716d145b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"models/rugpt3small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d943f21c-f1ba-4102-a9a5-d504e37ebb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Вопрос: Что такое учебный центр Neoflex? Ответ:  Мы предоставляем студентам, выпускникам вузов отличные возможности для получения необходимых знаний для старта карьеры. Занятия в «Учебном центре» проводят опытные преподаватели из числа ведущих сотрудников Neoflex. Обучение проводится в онлайн-формате. Лучшие выпускники курсов получают возможность стать частью нашего большого дружного коллектива и развиваться в уникальной профессиональной среде. Лучшие выпускники курсов получают возможность стать частью нашего большого дружного коллектива и развиваться в уникальной профессиональной среде. Лучшие выпускники курсов получают возможность стать частью нашего большого дружного коллектива и развиваться в уникальной профессиональной среде. Занятия в «Учебном центре» проводят опытные преподаватели из числа ведущих сотрудников Neoflex. Занятия проводятся в онлайн-формате. Лучшие выпускники курсов получают возможность стать частью нашего большого дружного коллектива и развиваться в уникальной профессиональной среде. Лучшие выпускники курсов получают возможность стать частью нашего большого дружного коллектива и развиваться в уникальной профессиональной среде. Лучшие выпускники курсов получают возможность стать частью нашего большого дружного коллектива и развиваться'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Вопрос: Что такое учебный центр Neoflex? Ответ: \", do_sample=True, max_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed573fe3-d5f3-45d6-a43d-fa1720dc0e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8341307-e0bf-4d74-811b-758fdeca4f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = GPT2Tokenizer.from_pretrained(\"models/rugpt3small\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"models/rugpt3small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e24f7b4-8169-4192-8a33-1b54dd307de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50264, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50264, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bbd7eb7-fe82-4647-a448-ae4934dd1ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Вопрос: Что такое учебный центр Neoflex? Ответ: \"\n",
    "inpt = tok.encode(text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "879de5b1-cdf8-4a92-8065-b7923e38198b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Вопрос: Что такое учебный центр Neoflex? Ответ:  Мы предоставляем студентам и выпускникам вузов отличные возможности для получения необходимых знаний для старта карьеры. Занятия в «Учебном центре» проводят опытные преподаватели из числа ведущих сотрудников Neofax. Обучение проводится в онлайн-формате. Лучшие выпускники курсов получают возможность стать частью нашего большого дружного коллектива и развиваться в уникальной профессиональной среде. Наш отраслевой опыт и технологическая экспертиза, усиленная собственными акселераторами разработки, позволяют решать бизнес-'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.generate(\n",
    "    inpt.cuda(), \n",
    "    max_length=100,\n",
    "    repetition_penalty=7.0,\n",
    "    do_sample=True,\n",
    "    top_k=5, \n",
    "    top_p=0.95, \n",
    "    temperature=1,\n",
    "    num_beams=10, \n",
    "    no_repeat_ngram_size=3\n",
    ")\n",
    "\n",
    "tok.decode(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673abff9-fc58-4c53-9425-09014e64ca76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39f7593-3581-4130-a95c-0b092b3a000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bash_task = BashOperator(\n",
    "    task_id=\"bash_task\",\n",
    "    bash_command='''\n",
    "    !python run_clm.py \\\n",
    "    --model_name_or_path sberbank-ai/rugpt3small_based_on_gpt2 \\\n",
    "    --train_file train.txt \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --block_size 2048 \\\n",
    "    --dataset_config_name plain_text \\\n",
    "    --do_train \\\n",
    "    --num_train_epochs 12 \\\n",
    "    --output_dir models/rugpt3small \\\n",
    "    --overwrite_output_dir\n",
    "    ''',\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
